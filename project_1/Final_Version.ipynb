{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyod.models.iforest import IForest\n",
    "import sklearn.ensemble as ensemble\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn import tree,linear_model,svm,neighbors,ensemble  \n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import RidgeCV,LassoCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.svm import SVR\n",
    "import warnings\n",
    "import statistics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "\n",
    "train_x = pd.read_csv(\"X_train.csv\")\n",
    "train_y = pd.read_csv(\"y_train.csv\")\n",
    "test_x = pd.read_csv(\"X_test.csv\")\n",
    "\n",
    "# pre-selection\n",
    "train_x_imputed = train_x.fillna(train_x.median())\n",
    "test_x_imputed = test_x.fillna(test_x.median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.891876</td>\n",
       "      <td>832442.812375</td>\n",
       "      <td>20585.544083</td>\n",
       "      <td>1028.369495</td>\n",
       "      <td>1.163780e+06</td>\n",
       "      <td>9.199135</td>\n",
       "      <td>597900.477629</td>\n",
       "      <td>10295.013382</td>\n",
       "      <td>1.144294e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024198e+06</td>\n",
       "      <td>-855.549602</td>\n",
       "      <td>12176.073427</td>\n",
       "      <td>10.647729</td>\n",
       "      <td>10.916371</td>\n",
       "      <td>1220.065443</td>\n",
       "      <td>8.566724</td>\n",
       "      <td>1.036263e+06</td>\n",
       "      <td>85338.558539</td>\n",
       "      <td>103088.664210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.512994</td>\n",
       "      <td>832442.898114</td>\n",
       "      <td>20585.524817</td>\n",
       "      <td>1012.624877</td>\n",
       "      <td>1.028911e+06</td>\n",
       "      <td>10.906408</td>\n",
       "      <td>597900.458612</td>\n",
       "      <td>8127.016078</td>\n",
       "      <td>1.099166e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.086806e+06</td>\n",
       "      <td>-787.397942</td>\n",
       "      <td>10493.095660</td>\n",
       "      <td>10.586492</td>\n",
       "      <td>9.463962</td>\n",
       "      <td>917.094909</td>\n",
       "      <td>10.231822</td>\n",
       "      <td>1.007163e+06</td>\n",
       "      <td>95695.020645</td>\n",
       "      <td>105161.109422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.052185</td>\n",
       "      <td>832442.896307</td>\n",
       "      <td>20585.512844</td>\n",
       "      <td>1003.953827</td>\n",
       "      <td>9.231756e+05</td>\n",
       "      <td>9.212979</td>\n",
       "      <td>597900.426764</td>\n",
       "      <td>10738.092422</td>\n",
       "      <td>1.027863e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018533e+06</td>\n",
       "      <td>-906.997242</td>\n",
       "      <td>10959.516944</td>\n",
       "      <td>10.769287</td>\n",
       "      <td>10.342160</td>\n",
       "      <td>637.027802</td>\n",
       "      <td>10.705461</td>\n",
       "      <td>1.019955e+06</td>\n",
       "      <td>80253.299882</td>\n",
       "      <td>104177.051666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>11.642076</td>\n",
       "      <td>832442.860041</td>\n",
       "      <td>20585.524817</td>\n",
       "      <td>1004.672084</td>\n",
       "      <td>9.459461e+05</td>\n",
       "      <td>9.553420</td>\n",
       "      <td>597900.450367</td>\n",
       "      <td>13524.096973</td>\n",
       "      <td>1.168144e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047017e+06</td>\n",
       "      <td>-1011.742516</td>\n",
       "      <td>16845.309819</td>\n",
       "      <td>10.483830</td>\n",
       "      <td>10.594941</td>\n",
       "      <td>1114.069590</td>\n",
       "      <td>10.321063</td>\n",
       "      <td>1.085442e+06</td>\n",
       "      <td>99802.127899</td>\n",
       "      <td>102746.516920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10.407121</td>\n",
       "      <td>832442.831424</td>\n",
       "      <td>20585.557007</td>\n",
       "      <td>1047.985497</td>\n",
       "      <td>9.957182e+05</td>\n",
       "      <td>8.419164</td>\n",
       "      <td>597900.423639</td>\n",
       "      <td>12894.065081</td>\n",
       "      <td>1.063199e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031009e+06</td>\n",
       "      <td>-1025.223865</td>\n",
       "      <td>18348.460040</td>\n",
       "      <td>10.554260</td>\n",
       "      <td>10.114370</td>\n",
       "      <td>1230.088215</td>\n",
       "      <td>10.250096</td>\n",
       "      <td>1.024812e+06</td>\n",
       "      <td>101815.745499</td>\n",
       "      <td>105163.749149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>771.0</td>\n",
       "      <td>8.643008</td>\n",
       "      <td>832442.901284</td>\n",
       "      <td>20585.516033</td>\n",
       "      <td>1049.164447</td>\n",
       "      <td>9.634039e+05</td>\n",
       "      <td>11.763651</td>\n",
       "      <td>597900.382191</td>\n",
       "      <td>12498.079536</td>\n",
       "      <td>9.646803e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036885e+06</td>\n",
       "      <td>-1096.877578</td>\n",
       "      <td>16780.272363</td>\n",
       "      <td>10.494413</td>\n",
       "      <td>10.985756</td>\n",
       "      <td>1482.074684</td>\n",
       "      <td>11.709038</td>\n",
       "      <td>1.007811e+06</td>\n",
       "      <td>98257.691777</td>\n",
       "      <td>107061.654854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>772.0</td>\n",
       "      <td>9.639356</td>\n",
       "      <td>832442.864233</td>\n",
       "      <td>20585.544425</td>\n",
       "      <td>1043.984958</td>\n",
       "      <td>1.147107e+06</td>\n",
       "      <td>11.144385</td>\n",
       "      <td>597900.460932</td>\n",
       "      <td>10499.010672</td>\n",
       "      <td>8.629803e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068757e+06</td>\n",
       "      <td>-942.034551</td>\n",
       "      <td>15097.913035</td>\n",
       "      <td>10.564327</td>\n",
       "      <td>10.691379</td>\n",
       "      <td>762.002833</td>\n",
       "      <td>9.960825</td>\n",
       "      <td>1.030335e+06</td>\n",
       "      <td>110688.236655</td>\n",
       "      <td>100730.307869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>773.0</td>\n",
       "      <td>10.091882</td>\n",
       "      <td>832442.904383</td>\n",
       "      <td>20585.515217</td>\n",
       "      <td>1017.114468</td>\n",
       "      <td>1.040988e+06</td>\n",
       "      <td>9.840801</td>\n",
       "      <td>597900.441911</td>\n",
       "      <td>11192.048851</td>\n",
       "      <td>9.575331e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.061697e+06</td>\n",
       "      <td>-989.876896</td>\n",
       "      <td>14143.508919</td>\n",
       "      <td>11.002609</td>\n",
       "      <td>11.177008</td>\n",
       "      <td>1047.546785</td>\n",
       "      <td>9.023443</td>\n",
       "      <td>1.045739e+06</td>\n",
       "      <td>103970.270645</td>\n",
       "      <td>108906.208766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>774.0</td>\n",
       "      <td>11.154426</td>\n",
       "      <td>832442.875082</td>\n",
       "      <td>20585.496750</td>\n",
       "      <td>1059.286367</td>\n",
       "      <td>9.187398e+05</td>\n",
       "      <td>9.500992</td>\n",
       "      <td>597900.388416</td>\n",
       "      <td>10931.010976</td>\n",
       "      <td>8.592437e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002105e+06</td>\n",
       "      <td>-848.755303</td>\n",
       "      <td>10119.058965</td>\n",
       "      <td>10.242841</td>\n",
       "      <td>8.894702</td>\n",
       "      <td>1044.042333</td>\n",
       "      <td>10.634034</td>\n",
       "      <td>1.071376e+06</td>\n",
       "      <td>92897.930814</td>\n",
       "      <td>108439.186933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>775.0</td>\n",
       "      <td>8.533177</td>\n",
       "      <td>832442.831184</td>\n",
       "      <td>20585.570098</td>\n",
       "      <td>1074.989310</td>\n",
       "      <td>9.302904e+05</td>\n",
       "      <td>10.868134</td>\n",
       "      <td>597900.419488</td>\n",
       "      <td>11405.053533</td>\n",
       "      <td>1.134763e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.030429e+06</td>\n",
       "      <td>-808.330122</td>\n",
       "      <td>14682.824536</td>\n",
       "      <td>10.508033</td>\n",
       "      <td>9.224802</td>\n",
       "      <td>1096.096410</td>\n",
       "      <td>9.516297</td>\n",
       "      <td>1.072168e+06</td>\n",
       "      <td>94952.659109</td>\n",
       "      <td>105023.965025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1988 rows × 833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         x0             x1            x2           x3            x4  \\\n",
       "0      0.0  10.891876  832442.812375  20585.544083  1028.369495  1.163780e+06   \n",
       "1      1.0  11.512994  832442.898114  20585.524817  1012.624877  1.028911e+06   \n",
       "2      2.0  11.052185  832442.896307  20585.512844  1003.953827  9.231756e+05   \n",
       "3      3.0  11.642076  832442.860041  20585.524817  1004.672084  9.459461e+05   \n",
       "4      4.0  10.407121  832442.831424  20585.557007  1047.985497  9.957182e+05   \n",
       "..     ...        ...            ...           ...          ...           ...   \n",
       "771  771.0   8.643008  832442.901284  20585.516033  1049.164447  9.634039e+05   \n",
       "772  772.0   9.639356  832442.864233  20585.544425  1043.984958  1.147107e+06   \n",
       "773  773.0  10.091882  832442.904383  20585.515217  1017.114468  1.040988e+06   \n",
       "774  774.0  11.154426  832442.875082  20585.496750  1059.286367  9.187398e+05   \n",
       "775  775.0   8.533177  832442.831184  20585.570098  1074.989310  9.302904e+05   \n",
       "\n",
       "            x5             x6            x7            x8  ...          x822  \\\n",
       "0     9.199135  597900.477629  10295.013382  1.144294e+06  ...  1.024198e+06   \n",
       "1    10.906408  597900.458612   8127.016078  1.099166e+06  ...  1.086806e+06   \n",
       "2     9.212979  597900.426764  10738.092422  1.027863e+06  ...  1.018533e+06   \n",
       "3     9.553420  597900.450367  13524.096973  1.168144e+06  ...  1.047017e+06   \n",
       "4     8.419164  597900.423639  12894.065081  1.063199e+06  ...  1.031009e+06   \n",
       "..         ...            ...           ...           ...  ...           ...   \n",
       "771  11.763651  597900.382191  12498.079536  9.646803e+05  ...  1.036885e+06   \n",
       "772  11.144385  597900.460932  10499.010672  8.629803e+05  ...  1.068757e+06   \n",
       "773   9.840801  597900.441911  11192.048851  9.575331e+05  ...  1.061697e+06   \n",
       "774   9.500992  597900.388416  10931.010976  8.592437e+05  ...  1.002105e+06   \n",
       "775  10.868134  597900.419488  11405.053533  1.134763e+06  ...  1.030429e+06   \n",
       "\n",
       "            x823          x824       x825       x826         x827       x828  \\\n",
       "0    -855.549602  12176.073427  10.647729  10.916371  1220.065443   8.566724   \n",
       "1    -787.397942  10493.095660  10.586492   9.463962   917.094909  10.231822   \n",
       "2    -906.997242  10959.516944  10.769287  10.342160   637.027802  10.705461   \n",
       "3   -1011.742516  16845.309819  10.483830  10.594941  1114.069590  10.321063   \n",
       "4   -1025.223865  18348.460040  10.554260  10.114370  1230.088215  10.250096   \n",
       "..           ...           ...        ...        ...          ...        ...   \n",
       "771 -1096.877578  16780.272363  10.494413  10.985756  1482.074684  11.709038   \n",
       "772  -942.034551  15097.913035  10.564327  10.691379   762.002833   9.960825   \n",
       "773  -989.876896  14143.508919  11.002609  11.177008  1047.546785   9.023443   \n",
       "774  -848.755303  10119.058965  10.242841   8.894702  1044.042333  10.634034   \n",
       "775  -808.330122  14682.824536  10.508033   9.224802  1096.096410   9.516297   \n",
       "\n",
       "             x829           x830           x831  \n",
       "0    1.036263e+06   85338.558539  103088.664210  \n",
       "1    1.007163e+06   95695.020645  105161.109422  \n",
       "2    1.019955e+06   80253.299882  104177.051666  \n",
       "3    1.085442e+06   99802.127899  102746.516920  \n",
       "4    1.024812e+06  101815.745499  105163.749149  \n",
       "..            ...            ...            ...  \n",
       "771  1.007811e+06   98257.691777  107061.654854  \n",
       "772  1.030335e+06  110688.236655  100730.307869  \n",
       "773  1.045739e+06  103970.270645  108906.208766  \n",
       "774  1.071376e+06   92897.930814  108439.186933  \n",
       "775  1.072168e+06   94952.659109  105023.965025  \n",
       "\n",
       "[1988 rows x 833 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_x = pd.concat([train_x_imputed,test_x_imputed], axis = 0)\n",
    "combined_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_x = combined_x.drop('id',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1988, 832)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_combined_x = combined_x.to_numpy()\n",
    "np_combined_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_combined_x += 1e-7\n",
    "x_var = np.var(np_combined_x/np.mean(np_combined_x,axis = 0), axis = 0)\n",
    "x_index = x_var > 1e-10\n",
    "np_combined_x -= 1e-7\n",
    "np_combined_preselected = np_combined_x[:,x_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "preselected_standarized = StandardScaler().fit_transform(np_combined_preselected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1212, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dropped = train_y.drop('id',axis = 1).to_numpy()\n",
    "y_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71.],\n",
       "       [73.],\n",
       "       [66.],\n",
       "       ...,\n",
       "       [82.],\n",
       "       [76.],\n",
       "       [81.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_preselected = preselected_standarized[:len(train_x_imputed)]\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "kbest= SelectKBest(score_func=f_classif, k=150)\n",
    "kbest.fit(x_train_preselected, y_dropped)\n",
    "x_selected = kbest.transform(x_train_preselected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(sum(x_index))\n",
    "index = kbest.transform(index.reshape((1, -1)))\n",
    "kbest_index_150 = index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing part with random forest\n",
    "combined = pd.concat([train_x,test_x], axis = 0)\n",
    "combined = combined.drop('id',axis = 1)\n",
    "missing_index = np.isnan(combined.to_numpy())\n",
    "\n",
    "missing_preselect = missing_index[:,x_index]\n",
    "missing_kbest = missing_preselect[:,kbest_index_150]\n",
    "\n",
    "x_train_standarized = preselected_standarized[:len(train_x)]\n",
    "x_test_standarzied = preselected_standarized[len(train_x):]\n",
    "standarzied_kbest = preselected_standarized[:,kbest_index_150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "            data_train =standarzied_kbest[missing_kbest[:, i] == 0]\n",
    "            data_test = standarzied_kbest[missing_kbest[:, i] == 1]\n",
    "            x = data_train[:, np.concatenate((np.arange(i), np.arange(i + 1, 150)))]\n",
    "            y = data_train[:, i]\n",
    "            x_test = data_test[:, np.concatenate((np.arange(i), np.arange(i + 1, 150)))]\n",
    "            random_forest = ensemble.RandomForestRegressor(n_estimators=20)\n",
    "            random_forest.fit(x, y)\n",
    "            standarzied_kbest[missing_kbest[:, i] == 1, i] = random_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_filled = standarzied_kbest[:len(train_x)]\n",
    "x_test_filled = standarzied_kbest[len(train_x):]\n",
    "np.save('x_filled_150.npy',x_train_filled)\n",
    "np.save('x_test_filled_150.npy',x_test_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utilize a specific random forest generated dataset to keep everything the same and save time (random forest imputation results differ from time to time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.067006</td>\n",
       "      <td>-1.293425</td>\n",
       "      <td>-1.403565</td>\n",
       "      <td>-0.752193</td>\n",
       "      <td>0.785924</td>\n",
       "      <td>-0.571447</td>\n",
       "      <td>-0.276164</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>-0.653109</td>\n",
       "      <td>-1.011140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720488</td>\n",
       "      <td>-1.456983</td>\n",
       "      <td>0.224129</td>\n",
       "      <td>-0.462247</td>\n",
       "      <td>-0.045539</td>\n",
       "      <td>-1.852063</td>\n",
       "      <td>-0.408639</td>\n",
       "      <td>0.606301</td>\n",
       "      <td>0.147695</td>\n",
       "      <td>-0.558470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.469999</td>\n",
       "      <td>0.773029</td>\n",
       "      <td>-1.160758</td>\n",
       "      <td>-2.384768</td>\n",
       "      <td>-0.234770</td>\n",
       "      <td>-1.298215</td>\n",
       "      <td>-3.968961</td>\n",
       "      <td>-3.920331</td>\n",
       "      <td>-0.852204</td>\n",
       "      <td>-3.227427</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.452378</td>\n",
       "      <td>-0.553620</td>\n",
       "      <td>-4.604982</td>\n",
       "      <td>-0.912848</td>\n",
       "      <td>-2.907321</td>\n",
       "      <td>2.005624</td>\n",
       "      <td>-2.809605</td>\n",
       "      <td>1.324355</td>\n",
       "      <td>0.599145</td>\n",
       "      <td>-1.296270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.248151</td>\n",
       "      <td>0.095817</td>\n",
       "      <td>-0.331348</td>\n",
       "      <td>1.710010</td>\n",
       "      <td>-0.852011</td>\n",
       "      <td>-1.140590</td>\n",
       "      <td>0.474671</td>\n",
       "      <td>0.675400</td>\n",
       "      <td>-0.452269</td>\n",
       "      <td>1.017093</td>\n",
       "      <td>...</td>\n",
       "      <td>1.285088</td>\n",
       "      <td>0.710090</td>\n",
       "      <td>2.336358</td>\n",
       "      <td>-0.527738</td>\n",
       "      <td>0.244477</td>\n",
       "      <td>-0.498429</td>\n",
       "      <td>1.312145</td>\n",
       "      <td>1.309645</td>\n",
       "      <td>-0.193105</td>\n",
       "      <td>-1.091796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.081409</td>\n",
       "      <td>1.765467</td>\n",
       "      <td>2.266001</td>\n",
       "      <td>2.262642</td>\n",
       "      <td>1.014391</td>\n",
       "      <td>1.462275</td>\n",
       "      <td>0.594757</td>\n",
       "      <td>1.729658</td>\n",
       "      <td>2.066897</td>\n",
       "      <td>2.069848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736901</td>\n",
       "      <td>2.166233</td>\n",
       "      <td>2.487331</td>\n",
       "      <td>0.788261</td>\n",
       "      <td>1.693366</td>\n",
       "      <td>1.066877</td>\n",
       "      <td>2.519459</td>\n",
       "      <td>-1.441200</td>\n",
       "      <td>-0.886959</td>\n",
       "      <td>1.488473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.666833</td>\n",
       "      <td>-0.402217</td>\n",
       "      <td>1.825465</td>\n",
       "      <td>0.093205</td>\n",
       "      <td>0.759559</td>\n",
       "      <td>2.133440</td>\n",
       "      <td>0.788909</td>\n",
       "      <td>1.071193</td>\n",
       "      <td>1.388511</td>\n",
       "      <td>0.794569</td>\n",
       "      <td>...</td>\n",
       "      <td>1.026589</td>\n",
       "      <td>0.735781</td>\n",
       "      <td>-0.020892</td>\n",
       "      <td>0.978279</td>\n",
       "      <td>0.232978</td>\n",
       "      <td>0.450529</td>\n",
       "      <td>0.284147</td>\n",
       "      <td>-2.170518</td>\n",
       "      <td>-0.976263</td>\n",
       "      <td>2.147437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>1.522846</td>\n",
       "      <td>0.797356</td>\n",
       "      <td>0.479127</td>\n",
       "      <td>0.679592</td>\n",
       "      <td>-0.289678</td>\n",
       "      <td>1.848432</td>\n",
       "      <td>1.064154</td>\n",
       "      <td>0.848504</td>\n",
       "      <td>1.669260</td>\n",
       "      <td>1.266909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546970</td>\n",
       "      <td>1.935008</td>\n",
       "      <td>1.150798</td>\n",
       "      <td>2.118225</td>\n",
       "      <td>0.416713</td>\n",
       "      <td>0.934763</td>\n",
       "      <td>1.878352</td>\n",
       "      <td>-1.890695</td>\n",
       "      <td>-0.805464</td>\n",
       "      <td>1.858508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>0.316553</td>\n",
       "      <td>2.376054</td>\n",
       "      <td>0.722423</td>\n",
       "      <td>1.526327</td>\n",
       "      <td>1.003326</td>\n",
       "      <td>1.036352</td>\n",
       "      <td>0.139742</td>\n",
       "      <td>0.310240</td>\n",
       "      <td>0.790403</td>\n",
       "      <td>1.288308</td>\n",
       "      <td>...</td>\n",
       "      <td>1.061305</td>\n",
       "      <td>0.392017</td>\n",
       "      <td>1.502281</td>\n",
       "      <td>1.164241</td>\n",
       "      <td>1.311924</td>\n",
       "      <td>0.570094</td>\n",
       "      <td>1.394910</td>\n",
       "      <td>-0.833109</td>\n",
       "      <td>-1.558192</td>\n",
       "      <td>1.115298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>-1.979360</td>\n",
       "      <td>-0.823153</td>\n",
       "      <td>-1.432517</td>\n",
       "      <td>-0.701362</td>\n",
       "      <td>-1.439913</td>\n",
       "      <td>-0.694137</td>\n",
       "      <td>-0.296712</td>\n",
       "      <td>-1.520557</td>\n",
       "      <td>-1.350726</td>\n",
       "      <td>-1.728302</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.730668</td>\n",
       "      <td>-0.302337</td>\n",
       "      <td>-1.124100</td>\n",
       "      <td>-0.764278</td>\n",
       "      <td>-1.199191</td>\n",
       "      <td>-0.597893</td>\n",
       "      <td>-1.367733</td>\n",
       "      <td>0.231197</td>\n",
       "      <td>2.621635</td>\n",
       "      <td>-0.837492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>1.816189</td>\n",
       "      <td>1.358641</td>\n",
       "      <td>2.106213</td>\n",
       "      <td>0.851736</td>\n",
       "      <td>-0.659798</td>\n",
       "      <td>0.658404</td>\n",
       "      <td>0.162908</td>\n",
       "      <td>0.657179</td>\n",
       "      <td>1.562514</td>\n",
       "      <td>0.889259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483502</td>\n",
       "      <td>1.372113</td>\n",
       "      <td>-0.063667</td>\n",
       "      <td>3.412383</td>\n",
       "      <td>0.555923</td>\n",
       "      <td>0.960407</td>\n",
       "      <td>0.427011</td>\n",
       "      <td>-0.479488</td>\n",
       "      <td>-1.230829</td>\n",
       "      <td>0.727154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>-0.272364</td>\n",
       "      <td>-0.037505</td>\n",
       "      <td>0.032407</td>\n",
       "      <td>-0.865059</td>\n",
       "      <td>-0.773861</td>\n",
       "      <td>0.476497</td>\n",
       "      <td>-0.515022</td>\n",
       "      <td>1.737325</td>\n",
       "      <td>0.276515</td>\n",
       "      <td>0.065802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093261</td>\n",
       "      <td>-0.121104</td>\n",
       "      <td>-0.574983</td>\n",
       "      <td>0.158758</td>\n",
       "      <td>0.229742</td>\n",
       "      <td>0.066762</td>\n",
       "      <td>-0.140468</td>\n",
       "      <td>-0.556965</td>\n",
       "      <td>0.132974</td>\n",
       "      <td>0.463024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1212 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.067006 -1.293425 -1.403565 -0.752193  0.785924 -0.571447 -0.276164   \n",
       "1    -1.469999  0.773029 -1.160758 -2.384768 -0.234770 -1.298215 -3.968961   \n",
       "2     0.248151  0.095817 -0.331348  1.710010 -0.852011 -1.140590  0.474671   \n",
       "3     2.081409  1.765467  2.266001  2.262642  1.014391  1.462275  0.594757   \n",
       "4     1.666833 -0.402217  1.825465  0.093205  0.759559  2.133440  0.788909   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1207  1.522846  0.797356  0.479127  0.679592 -0.289678  1.848432  1.064154   \n",
       "1208  0.316553  2.376054  0.722423  1.526327  1.003326  1.036352  0.139742   \n",
       "1209 -1.979360 -0.823153 -1.432517 -0.701362 -1.439913 -0.694137 -0.296712   \n",
       "1210  1.816189  1.358641  2.106213  0.851736 -0.659798  0.658404  0.162908   \n",
       "1211 -0.272364 -0.037505  0.032407 -0.865059 -0.773861  0.476497 -0.515022   \n",
       "\n",
       "           7         8         9    ...       140       141       142  \\\n",
       "0     0.607955 -0.653109 -1.011140  ... -0.720488 -1.456983  0.224129   \n",
       "1    -3.920331 -0.852204 -3.227427  ... -1.452378 -0.553620 -4.604982   \n",
       "2     0.675400 -0.452269  1.017093  ...  1.285088  0.710090  2.336358   \n",
       "3     1.729658  2.066897  2.069848  ...  0.736901  2.166233  2.487331   \n",
       "4     1.071193  1.388511  0.794569  ...  1.026589  0.735781 -0.020892   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1207  0.848504  1.669260  1.266909  ...  0.546970  1.935008  1.150798   \n",
       "1208  0.310240  0.790403  1.288308  ...  1.061305  0.392017  1.502281   \n",
       "1209 -1.520557 -1.350726 -1.728302  ... -1.730668 -0.302337 -1.124100   \n",
       "1210  0.657179  1.562514  0.889259  ...  0.483502  1.372113 -0.063667   \n",
       "1211  1.737325  0.276515  0.065802  ... -0.093261 -0.121104 -0.574983   \n",
       "\n",
       "           143       144       145       146       147       148       149  \n",
       "0    -0.462247 -0.045539 -1.852063 -0.408639  0.606301  0.147695 -0.558470  \n",
       "1    -0.912848 -2.907321  2.005624 -2.809605  1.324355  0.599145 -1.296270  \n",
       "2    -0.527738  0.244477 -0.498429  1.312145  1.309645 -0.193105 -1.091796  \n",
       "3     0.788261  1.693366  1.066877  2.519459 -1.441200 -0.886959  1.488473  \n",
       "4     0.978279  0.232978  0.450529  0.284147 -2.170518 -0.976263  2.147437  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1207  2.118225  0.416713  0.934763  1.878352 -1.890695 -0.805464  1.858508  \n",
       "1208  1.164241  1.311924  0.570094  1.394910 -0.833109 -1.558192  1.115298  \n",
       "1209 -0.764278 -1.199191 -0.597893 -1.367733  0.231197  2.621635 -0.837492  \n",
       "1210  3.412383  0.555923  0.960407  0.427011 -0.479488 -1.230829  0.727154  \n",
       "1211  0.158758  0.229742  0.066762 -0.140468 -0.556965  0.132974  0.463024  \n",
       "\n",
       "[1212 rows x 150 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_filled = np.load('x_filled_random_forest_150.npy')\n",
    "pd.DataFrame(x_train_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283004</td>\n",
       "      <td>0.393895</td>\n",
       "      <td>-0.701723</td>\n",
       "      <td>-0.019336</td>\n",
       "      <td>1.143775</td>\n",
       "      <td>-0.990787</td>\n",
       "      <td>0.593992</td>\n",
       "      <td>1.081655</td>\n",
       "      <td>1.019764</td>\n",
       "      <td>-0.173057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.309378</td>\n",
       "      <td>0.141915</td>\n",
       "      <td>-1.108366</td>\n",
       "      <td>1.356631</td>\n",
       "      <td>0.378535</td>\n",
       "      <td>0.254133</td>\n",
       "      <td>0.358797</td>\n",
       "      <td>1.276945</td>\n",
       "      <td>-0.824324</td>\n",
       "      <td>-0.903857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.026285</td>\n",
       "      <td>0.541333</td>\n",
       "      <td>-0.061505</td>\n",
       "      <td>0.214694</td>\n",
       "      <td>0.267189</td>\n",
       "      <td>0.938926</td>\n",
       "      <td>0.826456</td>\n",
       "      <td>0.651093</td>\n",
       "      <td>0.334588</td>\n",
       "      <td>0.176864</td>\n",
       "      <td>...</td>\n",
       "      <td>1.704390</td>\n",
       "      <td>0.058003</td>\n",
       "      <td>-0.036650</td>\n",
       "      <td>0.651784</td>\n",
       "      <td>0.850816</td>\n",
       "      <td>-0.672572</td>\n",
       "      <td>0.597514</td>\n",
       "      <td>-1.179471</td>\n",
       "      <td>0.666992</td>\n",
       "      <td>0.878960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.636262</td>\n",
       "      <td>-0.248033</td>\n",
       "      <td>0.907850</td>\n",
       "      <td>-0.420359</td>\n",
       "      <td>1.398358</td>\n",
       "      <td>0.072832</td>\n",
       "      <td>-1.212623</td>\n",
       "      <td>0.891306</td>\n",
       "      <td>-0.285484</td>\n",
       "      <td>-0.590058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262110</td>\n",
       "      <td>-0.800316</td>\n",
       "      <td>-0.646663</td>\n",
       "      <td>-0.239720</td>\n",
       "      <td>-0.609480</td>\n",
       "      <td>-0.024626</td>\n",
       "      <td>-0.493969</td>\n",
       "      <td>-0.095786</td>\n",
       "      <td>0.077080</td>\n",
       "      <td>0.072913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183624</td>\n",
       "      <td>1.158711</td>\n",
       "      <td>1.134022</td>\n",
       "      <td>0.101583</td>\n",
       "      <td>-0.224763</td>\n",
       "      <td>0.481676</td>\n",
       "      <td>-0.132390</td>\n",
       "      <td>-0.098889</td>\n",
       "      <td>1.199175</td>\n",
       "      <td>-0.222020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527875</td>\n",
       "      <td>1.944100</td>\n",
       "      <td>-0.378860</td>\n",
       "      <td>1.555416</td>\n",
       "      <td>-0.384747</td>\n",
       "      <td>0.344415</td>\n",
       "      <td>0.252019</td>\n",
       "      <td>-0.451370</td>\n",
       "      <td>-0.406746</td>\n",
       "      <td>0.502557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067833</td>\n",
       "      <td>0.779854</td>\n",
       "      <td>0.318337</td>\n",
       "      <td>1.177823</td>\n",
       "      <td>0.102110</td>\n",
       "      <td>0.318433</td>\n",
       "      <td>1.286779</td>\n",
       "      <td>0.362424</td>\n",
       "      <td>-0.034634</td>\n",
       "      <td>-0.405409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294231</td>\n",
       "      <td>-0.526184</td>\n",
       "      <td>0.514367</td>\n",
       "      <td>-0.034114</td>\n",
       "      <td>0.637459</td>\n",
       "      <td>-0.542146</td>\n",
       "      <td>-0.365107</td>\n",
       "      <td>-0.144378</td>\n",
       "      <td>-1.029844</td>\n",
       "      <td>0.381924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>1.406265</td>\n",
       "      <td>1.835712</td>\n",
       "      <td>1.098948</td>\n",
       "      <td>1.450787</td>\n",
       "      <td>0.507072</td>\n",
       "      <td>1.396482</td>\n",
       "      <td>1.405842</td>\n",
       "      <td>1.622259</td>\n",
       "      <td>1.515080</td>\n",
       "      <td>1.311798</td>\n",
       "      <td>...</td>\n",
       "      <td>1.459262</td>\n",
       "      <td>1.864717</td>\n",
       "      <td>0.587221</td>\n",
       "      <td>1.324934</td>\n",
       "      <td>1.952536</td>\n",
       "      <td>1.882977</td>\n",
       "      <td>0.970651</td>\n",
       "      <td>-1.253905</td>\n",
       "      <td>-1.450912</td>\n",
       "      <td>1.459961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0.090830</td>\n",
       "      <td>0.169374</td>\n",
       "      <td>1.595927</td>\n",
       "      <td>-1.765820</td>\n",
       "      <td>0.085927</td>\n",
       "      <td>0.706458</td>\n",
       "      <td>-1.212707</td>\n",
       "      <td>-0.068065</td>\n",
       "      <td>0.955148</td>\n",
       "      <td>-0.326406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244515</td>\n",
       "      <td>0.683263</td>\n",
       "      <td>-0.964681</td>\n",
       "      <td>0.844034</td>\n",
       "      <td>-0.412458</td>\n",
       "      <td>0.352048</td>\n",
       "      <td>-0.519692</td>\n",
       "      <td>-0.693807</td>\n",
       "      <td>-0.425199</td>\n",
       "      <td>0.722433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>0.546865</td>\n",
       "      <td>0.751724</td>\n",
       "      <td>-0.051563</td>\n",
       "      <td>-0.456691</td>\n",
       "      <td>-0.780042</td>\n",
       "      <td>0.256389</td>\n",
       "      <td>-1.287434</td>\n",
       "      <td>-0.495091</td>\n",
       "      <td>0.512019</td>\n",
       "      <td>-1.003578</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.136913</td>\n",
       "      <td>0.532488</td>\n",
       "      <td>-0.382298</td>\n",
       "      <td>-0.581733</td>\n",
       "      <td>-0.756550</td>\n",
       "      <td>0.171576</td>\n",
       "      <td>-1.220467</td>\n",
       "      <td>-0.132562</td>\n",
       "      <td>-0.742117</td>\n",
       "      <td>0.304032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0.375096</td>\n",
       "      <td>0.779996</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>-0.726173</td>\n",
       "      <td>0.441715</td>\n",
       "      <td>-1.494393</td>\n",
       "      <td>0.287215</td>\n",
       "      <td>-0.109627</td>\n",
       "      <td>0.421050</td>\n",
       "      <td>-0.084022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207047</td>\n",
       "      <td>0.316072</td>\n",
       "      <td>0.267792</td>\n",
       "      <td>0.509293</td>\n",
       "      <td>0.310094</td>\n",
       "      <td>0.655086</td>\n",
       "      <td>-0.668906</td>\n",
       "      <td>1.624490</td>\n",
       "      <td>0.192702</td>\n",
       "      <td>-1.460243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.687028</td>\n",
       "      <td>-0.002210</td>\n",
       "      <td>-0.252614</td>\n",
       "      <td>-0.600084</td>\n",
       "      <td>0.541052</td>\n",
       "      <td>0.577094</td>\n",
       "      <td>-0.892748</td>\n",
       "      <td>-0.726783</td>\n",
       "      <td>-0.246123</td>\n",
       "      <td>-0.411423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303468</td>\n",
       "      <td>-0.757478</td>\n",
       "      <td>-1.302683</td>\n",
       "      <td>-0.744252</td>\n",
       "      <td>-0.868366</td>\n",
       "      <td>-0.765169</td>\n",
       "      <td>-0.298897</td>\n",
       "      <td>-0.734251</td>\n",
       "      <td>0.460486</td>\n",
       "      <td>0.540462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>776 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.283004  0.393895 -0.701723 -0.019336  1.143775 -0.990787  0.593992   \n",
       "1   -0.026285  0.541333 -0.061505  0.214694  0.267189  0.938926  0.826456   \n",
       "2   -0.636262 -0.248033  0.907850 -0.420359  1.398358  0.072832 -1.212623   \n",
       "3    0.183624  1.158711  1.134022  0.101583 -0.224763  0.481676 -0.132390   \n",
       "4    0.067833  0.779854  0.318337  1.177823  0.102110  0.318433  1.286779   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "771  1.406265  1.835712  1.098948  1.450787  0.507072  1.396482  1.405842   \n",
       "772  0.090830  0.169374  1.595927 -1.765820  0.085927  0.706458 -1.212707   \n",
       "773  0.546865  0.751724 -0.051563 -0.456691 -0.780042  0.256389 -1.287434   \n",
       "774  0.375096  0.779996  0.036200 -0.726173  0.441715 -1.494393  0.287215   \n",
       "775  0.687028 -0.002210 -0.252614 -0.600084  0.541052  0.577094 -0.892748   \n",
       "\n",
       "          7         8         9    ...       140       141       142  \\\n",
       "0    1.081655  1.019764 -0.173057  ... -0.309378  0.141915 -1.108366   \n",
       "1    0.651093  0.334588  0.176864  ...  1.704390  0.058003 -0.036650   \n",
       "2    0.891306 -0.285484 -0.590058  ...  0.262110 -0.800316 -0.646663   \n",
       "3   -0.098889  1.199175 -0.222020  ... -0.527875  1.944100 -0.378860   \n",
       "4    0.362424 -0.034634 -0.405409  ... -0.294231 -0.526184  0.514367   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "771  1.622259  1.515080  1.311798  ...  1.459262  1.864717  0.587221   \n",
       "772 -0.068065  0.955148 -0.326406  ... -0.244515  0.683263 -0.964681   \n",
       "773 -0.495091  0.512019 -1.003578  ... -1.136913  0.532488 -0.382298   \n",
       "774 -0.109627  0.421050 -0.084022  ...  0.207047  0.316072  0.267792   \n",
       "775 -0.726783 -0.246123 -0.411423  ...  0.303468 -0.757478 -1.302683   \n",
       "\n",
       "          143       144       145       146       147       148       149  \n",
       "0    1.356631  0.378535  0.254133  0.358797  1.276945 -0.824324 -0.903857  \n",
       "1    0.651784  0.850816 -0.672572  0.597514 -1.179471  0.666992  0.878960  \n",
       "2   -0.239720 -0.609480 -0.024626 -0.493969 -0.095786  0.077080  0.072913  \n",
       "3    1.555416 -0.384747  0.344415  0.252019 -0.451370 -0.406746  0.502557  \n",
       "4   -0.034114  0.637459 -0.542146 -0.365107 -0.144378 -1.029844  0.381924  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "771  1.324934  1.952536  1.882977  0.970651 -1.253905 -1.450912  1.459961  \n",
       "772  0.844034 -0.412458  0.352048 -0.519692 -0.693807 -0.425199  0.722433  \n",
       "773 -0.581733 -0.756550  0.171576 -1.220467 -0.132562 -0.742117  0.304032  \n",
       "774  0.509293  0.310094  0.655086 -0.668906  1.624490  0.192702 -1.460243  \n",
       "775 -0.744252 -0.868366 -0.765169 -0.298897 -0.734251  0.460486  0.540462  \n",
       "\n",
       "[776 rows x 150 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_filled = np.load('x_test_filled_random_forest_150.npy')\n",
    "pd.DataFrame(x_test_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = IForest(contamination=0.04, random_state=42)\n",
    "classifier.fit(x_train_filled)\n",
    "outliers_detect = classifier.predict(x_train_filled)\n",
    "id_outlier = [i for i in range(0, 1212) if outliers_detect[i] == 1]\n",
    "len(id_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_clean = np.delete(x_train_filled, id_outlier, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_clean = np.delete(y_dropped, id_outlier, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1163, 150)\n",
      "(1163, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_clean.shape)\n",
    "print(y_train_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_slector = linear_model.Lasso(alpha=0.01)\n",
    "selector = SelectFromModel(lasso_slector.fit(x_train_clean, y_train_clean),prefit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_select = selector.transform(x_train_clean)\n",
    "x_test_select = selector.transform(x_test_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1163, 117)\n",
      "(776, 117)\n"
     ]
    }
   ],
   "source": [
    "print(x_select.shape)\n",
    "print(x_test_select.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1163, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_select = y_train_clean\n",
    "y_select.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking model\n",
    "\n",
    "model_names = []\n",
    "models = []\n",
    "\n",
    "model_LinearRegression = linear_model.LinearRegression()\n",
    "model_names.append(\"Linear Regression\")\n",
    "models.append(model_LinearRegression)\n",
    "\n",
    "    # 2\n",
    "model_SVR = SVR(kernel = 'rbf',C= 35, epsilon= 0.008, gamma=0.008)\n",
    "model_names.append(\"Support Vector Machine Regression\")\n",
    "models.append(model_SVR)\n",
    "\n",
    "   # 3\n",
    "model_KNeighborsRegressor = neighbors.KNeighborsRegressor(leaf_size=11, p=2,n_neighbors = 4,algorithm='brute',weights='distance')\n",
    "model_names.append(\"K-Nearest Neighbor Regression\")\n",
    "models.append(model_KNeighborsRegressor)\n",
    "\n",
    "    # 4\n",
    "# model_RandomForestRegressor = ensemble.RandomForestRegressor(n_estimators=20)\n",
    "# model_names.append(\"Random Forest Regression\")\n",
    "# models.append(model_RandomForestRegressor)\n",
    "\n",
    "# adaboost\n",
    "model_AdaBoostRegressor = ensemble.AdaBoostRegressor(base_estimator=tree.DecisionTreeRegressor(), random_state=42, n_estimators=2000,loss='linear',learning_rate = 0.3)\n",
    "#model_AdaBoostRegressor = ensemble.AdaBoostRegressor(base_estimator=ExtraTreeRegressor(ccp_alpha=0.0,max_features='auto', \n",
    "#                                                                                       min_impurity_decrease=0.0,\n",
    "#                                                                                       min_samples_leaf=1, \n",
    "#                                                                                       min_samples_split=2,\n",
    "#                                                                                       min_weight_fraction_leaf=0.0, \n",
    "#                                                                                       random_state=666,splitter='random'), \n",
    "#                                                     random_state=42, n_estimators=1500,loss='linear',learning_rate = 0.4)\n",
    "model_names.append(\"AdaBoost Regression\")\n",
    "models.append(model_AdaBoostRegressor)\n",
    "\n",
    "# gradient boosting\n",
    "model_GradientBoostingRegressor = ensemble.GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                            max_depth=4, max_features='sqrt',\n",
    "                                            min_samples_leaf=15, min_samples_split=10,\n",
    "                                            loss='huber', random_state =5)\n",
    "model_names.append(\"Gradient Boosting Regression\")\n",
    "models.append(model_GradientBoostingRegressor)\n",
    "\n",
    "     # 8\n",
    "model_ExtraTreeRegressor = ensemble.ExtraTreesRegressor(n_jobs=1, max_depth=15, n_estimators=195, random_state=0, min_samples_split=3, max_features=None)\n",
    "model_names.append(\"ExtraTree Regression\")\n",
    "models.append(model_ExtraTreeRegressor)\n",
    "\n",
    "       # 9\n",
    "model_XGBoostRegressor = xgb.XGBRegressor(learning_rate=0.01,n_estimators=3000,max_depth=4,min_child_weight=0,gamma=0.6,\n",
    "                                            subsample=0.7,colsample_bytree=0.7,nthread=-1,scale_pos_weight=1,seed=1,reg_alpha=0.00006,random_state=1)\n",
    "model_names.append(\"XGBoost Regression\")\n",
    "models.append(model_XGBoostRegressor)\n",
    "\n",
    "model_lasso = linear_model.LassoCV(cv=5, random_state=100)\n",
    "model_names.append(\"Lasso Regression\")\n",
    "models.append(model_lasso)\n",
    "\n",
    "model_ridge = linear_model.RidgeCV(cv=5)\n",
    "\n",
    "model_KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "model_names.append(\"Kernel Ridge Regression\")\n",
    "models.append(model_KRR)\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "model_names.append('LGBM Regressor')\n",
    "models.append(model_lgb)\n",
    "\n",
    "model_mlp = MLPRegressor(activation = 'identity',learning_rate_init = 0.0001, batch_size = 24,\n",
    "                    alpha = 0.001, random_state=1, max_iter=500)\n",
    "model_names.append('MLP Regressor')\n",
    "models.append(model_mlp)\n",
    "\n",
    "kernel = 8*Matern(nu=1.5)\n",
    "gpr = GaussianProcessRegressor(kernel = kernel, alpha=5e-9, optimizer='fmin_l_bfgs_b', normalize_y=True,random_state=666)\n",
    "model_names.append('Gaussian')\n",
    "models.append(gpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "score:  0.6904116445645695\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "score:  0.6478741955768405\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "score:  0.7153178604124563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "score:  0.7276531442404763\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "score:  0.6948488276954488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6904116445645695,\n",
       " 0.6478741955768405,\n",
       " 0.7153178604124563,\n",
       " 0.7276531442404763,\n",
       " 0.6948488276954488]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = list(zip(model_names,models))\n",
    "\n",
    "stacked = StackingRegressor(estimators=est,final_estimator = model_ridge)\n",
    "\n",
    "score_func = r2_score\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "score = []\n",
    "for train_idx, test_idx in kf.split(x_select):\n",
    "    x_train = x_select[train_idx]\n",
    "    y_train = y_select[train_idx]\n",
    "    x_test = x_select[test_idx]\n",
    "    y_test = y_select[test_idx]\n",
    "    stacked.fit(x_train,y_train)\n",
    "    s = stacked.score(x_test,y_test)\n",
    "    print('score: ', s)\n",
    "    score.append(s)\n",
    "\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6952211344979583"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(score)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    }
   ],
   "source": [
    "stacked.fit(x_select,y_select)\n",
    "stacked_pred = stacked.predict(x_test_select)\n",
    "\n",
    "model_XGBoostRegressor.fit(x_select,y_select)\n",
    "xgb_pred = model_XGBoostRegressor.predict(x_test_select)\n",
    "\n",
    "#model_lgb.fit(x_select,y_select)\n",
    "#lgb_pred = model_lgb.predict(x_test_select)\n",
    "\n",
    "gpr.fit(x_select,y_select)\n",
    "gpr_pred = gpr.predict(x_test_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_with_gaussian = pd.DataFrame(stacked_pred).to_numpy()*0.6+pd.DataFrame(xgb_pred).to_numpy()*0.15+gpr_pred*0.25\n",
    "pd.DataFrame(final_pred_with_gaussian).to_csv('submission_stack(ridge)_gaussian_weighted_0.25.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
